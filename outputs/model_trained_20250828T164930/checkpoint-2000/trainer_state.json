{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 285.7142857142857,
  "eval_steps": 200,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 7.142857142857143,
      "grad_norm": 15.269386291503906,
      "learning_rate": 2.45e-05,
      "loss": 13.0195,
      "step": 50
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 4.2933220863342285,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 11.1953,
      "step": 100
    },
    {
      "epoch": 21.428571428571427,
      "grad_norm": 3.6234383583068848,
      "learning_rate": 7.450000000000001e-05,
      "loss": 9.1092,
      "step": 150
    },
    {
      "epoch": 28.571428571428573,
      "grad_norm": 3.7709450721740723,
      "learning_rate": 9.95e-05,
      "loss": 7.5898,
      "step": 200
    },
    {
      "epoch": 28.571428571428573,
      "eval_accuracy": 0.3813084112149533,
      "eval_loss": 10.37960147857666,
      "eval_runtime": 0.4238,
      "eval_samples_per_second": 16409.151,
      "eval_steps_per_second": 9.437,
      "step": 200
    },
    {
      "epoch": 35.714285714285715,
      "grad_norm": 3.8169472217559814,
      "learning_rate": 9.851515151515151e-05,
      "loss": 6.6512,
      "step": 250
    },
    {
      "epoch": 42.857142857142854,
      "grad_norm": 3.7602877616882324,
      "learning_rate": 9.7e-05,
      "loss": 6.0912,
      "step": 300
    },
    {
      "epoch": 50.0,
      "grad_norm": 3.719573974609375,
      "learning_rate": 9.548484848484849e-05,
      "loss": 5.7087,
      "step": 350
    },
    {
      "epoch": 57.142857142857146,
      "grad_norm": 3.7199697494506836,
      "learning_rate": 9.396969696969697e-05,
      "loss": 5.4278,
      "step": 400
    },
    {
      "epoch": 57.142857142857146,
      "eval_accuracy": 0.41552839683680803,
      "eval_loss": 10.021697044372559,
      "eval_runtime": 0.5753,
      "eval_samples_per_second": 12089.425,
      "eval_steps_per_second": 6.953,
      "step": 400
    },
    {
      "epoch": 64.28571428571429,
      "grad_norm": 3.8302061557769775,
      "learning_rate": 9.245454545454546e-05,
      "loss": 5.2122,
      "step": 450
    },
    {
      "epoch": 71.42857142857143,
      "grad_norm": 3.6975951194763184,
      "learning_rate": 9.093939393939394e-05,
      "loss": 5.0262,
      "step": 500
    },
    {
      "epoch": 78.57142857142857,
      "grad_norm": 3.761523962020874,
      "learning_rate": 8.942424242424243e-05,
      "loss": 4.8667,
      "step": 550
    },
    {
      "epoch": 85.71428571428571,
      "grad_norm": 3.64904522895813,
      "learning_rate": 8.790909090909091e-05,
      "loss": 4.7324,
      "step": 600
    },
    {
      "epoch": 85.71428571428571,
      "eval_accuracy": 0.42386772106398274,
      "eval_loss": 9.869736671447754,
      "eval_runtime": 0.416,
      "eval_samples_per_second": 16719.502,
      "eval_steps_per_second": 9.616,
      "step": 600
    },
    {
      "epoch": 92.85714285714286,
      "grad_norm": 3.639603853225708,
      "learning_rate": 8.63939393939394e-05,
      "loss": 4.6091,
      "step": 650
    },
    {
      "epoch": 100.0,
      "grad_norm": 3.705305576324463,
      "learning_rate": 8.487878787878788e-05,
      "loss": 4.4957,
      "step": 700
    },
    {
      "epoch": 107.14285714285714,
      "grad_norm": 3.7005276679992676,
      "learning_rate": 8.336363636363637e-05,
      "loss": 4.3957,
      "step": 750
    },
    {
      "epoch": 114.28571428571429,
      "grad_norm": 3.614569902420044,
      "learning_rate": 8.184848484848485e-05,
      "loss": 4.3048,
      "step": 800
    },
    {
      "epoch": 114.28571428571429,
      "eval_accuracy": 0.4290438533429188,
      "eval_loss": 9.764688491821289,
      "eval_runtime": 0.3649,
      "eval_samples_per_second": 19062.377,
      "eval_steps_per_second": 10.963,
      "step": 800
    },
    {
      "epoch": 121.42857142857143,
      "grad_norm": 3.703247547149658,
      "learning_rate": 8.033333333333334e-05,
      "loss": 4.2225,
      "step": 850
    },
    {
      "epoch": 128.57142857142858,
      "grad_norm": 3.513625144958496,
      "learning_rate": 7.881818181818182e-05,
      "loss": 4.1444,
      "step": 900
    },
    {
      "epoch": 135.71428571428572,
      "grad_norm": 3.576181650161743,
      "learning_rate": 7.730303030303031e-05,
      "loss": 4.0726,
      "step": 950
    },
    {
      "epoch": 142.85714285714286,
      "grad_norm": 3.535104274749756,
      "learning_rate": 7.57878787878788e-05,
      "loss": 4.0094,
      "step": 1000
    },
    {
      "epoch": 142.85714285714286,
      "eval_accuracy": 0.4306254493170381,
      "eval_loss": 9.693707466125488,
      "eval_runtime": 0.537,
      "eval_samples_per_second": 12951.952,
      "eval_steps_per_second": 7.449,
      "step": 1000
    },
    {
      "epoch": 150.0,
      "grad_norm": 3.512385606765747,
      "learning_rate": 7.427272727272727e-05,
      "loss": 3.9443,
      "step": 1050
    },
    {
      "epoch": 157.14285714285714,
      "grad_norm": 3.4862866401672363,
      "learning_rate": 7.275757575757575e-05,
      "loss": 3.8889,
      "step": 1100
    },
    {
      "epoch": 164.28571428571428,
      "grad_norm": 3.5405211448669434,
      "learning_rate": 7.124242424242424e-05,
      "loss": 3.833,
      "step": 1150
    },
    {
      "epoch": 171.42857142857142,
      "grad_norm": 3.485283136367798,
      "learning_rate": 6.972727272727274e-05,
      "loss": 3.7777,
      "step": 1200
    },
    {
      "epoch": 171.42857142857142,
      "eval_accuracy": 0.43134435657800146,
      "eval_loss": 9.597362518310547,
      "eval_runtime": 0.4161,
      "eval_samples_per_second": 16713.4,
      "eval_steps_per_second": 9.612,
      "step": 1200
    },
    {
      "epoch": 178.57142857142858,
      "grad_norm": 3.3669793605804443,
      "learning_rate": 6.821212121212122e-05,
      "loss": 3.7294,
      "step": 1250
    },
    {
      "epoch": 185.71428571428572,
      "grad_norm": 3.4220170974731445,
      "learning_rate": 6.669696969696971e-05,
      "loss": 3.6834,
      "step": 1300
    },
    {
      "epoch": 192.85714285714286,
      "grad_norm": 3.488722562789917,
      "learning_rate": 6.518181818181819e-05,
      "loss": 3.64,
      "step": 1350
    },
    {
      "epoch": 200.0,
      "grad_norm": 3.393843173980713,
      "learning_rate": 6.366666666666668e-05,
      "loss": 3.5963,
      "step": 1400
    },
    {
      "epoch": 200.0,
      "eval_accuracy": 0.43033788641265275,
      "eval_loss": 9.546304702758789,
      "eval_runtime": 0.3626,
      "eval_samples_per_second": 19178.755,
      "eval_steps_per_second": 11.03,
      "step": 1400
    },
    {
      "epoch": 207.14285714285714,
      "grad_norm": 3.3770298957824707,
      "learning_rate": 6.215151515151515e-05,
      "loss": 3.5581,
      "step": 1450
    },
    {
      "epoch": 214.28571428571428,
      "grad_norm": 3.4232046604156494,
      "learning_rate": 6.0636363636363635e-05,
      "loss": 3.5196,
      "step": 1500
    },
    {
      "epoch": 221.42857142857142,
      "grad_norm": 3.267518997192383,
      "learning_rate": 5.912121212121212e-05,
      "loss": 3.4846,
      "step": 1550
    },
    {
      "epoch": 228.57142857142858,
      "grad_norm": 3.285090446472168,
      "learning_rate": 5.7606060606060606e-05,
      "loss": 3.449,
      "step": 1600
    },
    {
      "epoch": 228.57142857142858,
      "eval_accuracy": 0.4283249460819554,
      "eval_loss": 9.481513977050781,
      "eval_runtime": 0.5094,
      "eval_samples_per_second": 13653.723,
      "eval_steps_per_second": 7.853,
      "step": 1600
    },
    {
      "epoch": 235.71428571428572,
      "grad_norm": 3.2900872230529785,
      "learning_rate": 5.609090909090909e-05,
      "loss": 3.4168,
      "step": 1650
    },
    {
      "epoch": 242.85714285714286,
      "grad_norm": 3.2416164875030518,
      "learning_rate": 5.457575757575758e-05,
      "loss": 3.3846,
      "step": 1700
    },
    {
      "epoch": 250.0,
      "grad_norm": 3.2635457515716553,
      "learning_rate": 5.306060606060607e-05,
      "loss": 3.3547,
      "step": 1750
    },
    {
      "epoch": 257.14285714285717,
      "grad_norm": 3.3647682666778564,
      "learning_rate": 5.1545454545454555e-05,
      "loss": 3.3254,
      "step": 1800
    },
    {
      "epoch": 257.14285714285717,
      "eval_accuracy": 0.4291876347951114,
      "eval_loss": 9.418601036071777,
      "eval_runtime": 0.3644,
      "eval_samples_per_second": 19087.248,
      "eval_steps_per_second": 10.978,
      "step": 1800
    },
    {
      "epoch": 264.2857142857143,
      "grad_norm": 3.1664977073669434,
      "learning_rate": 5.0030303030303026e-05,
      "loss": 3.2973,
      "step": 1850
    },
    {
      "epoch": 271.42857142857144,
      "grad_norm": 3.3100194931030273,
      "learning_rate": 4.851515151515152e-05,
      "loss": 3.2698,
      "step": 1900
    },
    {
      "epoch": 278.57142857142856,
      "grad_norm": 3.3886215686798096,
      "learning_rate": 4.7e-05,
      "loss": 3.2448,
      "step": 1950
    },
    {
      "epoch": 285.7142857142857,
      "grad_norm": 3.2104527950286865,
      "learning_rate": 4.548484848484848e-05,
      "loss": 3.2214,
      "step": 2000
    },
    {
      "epoch": 285.7142857142857,
      "eval_accuracy": 0.43005032350826744,
      "eval_loss": 9.390580177307129,
      "eval_runtime": 0.416,
      "eval_samples_per_second": 16718.132,
      "eval_steps_per_second": 9.615,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 400,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 512,
  "trial_name": null,
  "trial_params": null
}
