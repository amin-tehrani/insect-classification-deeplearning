{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040e29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58c9996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amintehrani/.pyenv/versions/3.12.8/envs/torchgeo/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchviz\n",
    "# import dnabert\n",
    "# import vit\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import dataset\n",
    "import dnabert\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6b6392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'all_images', 'all_dnas', 'all_labels', 'all_dnas_norepeat', 'all_dna_labels_norepeat', 'all_boldids', 'train_loc', 'val_seen_loc', 'val_unseen_loc', 'test_seen_loc', 'test_unseen_loc', 'species2genus', 'described_species_labels_train', 'described_species_labels_trainval', 'all_dna_features_cnn_original', 'all_image_features_resnet', 'all_image_features_gan', 'all_dna_features_cnn_new', 'all_string_dnas'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAT_FILE_PATH = '/mnt/sdb4/insect_dataset.mat'\n",
    "\n",
    "mat = scipy.io.loadmat(MAT_FILE_PATH)\n",
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dna_dataset = DNADataset(mat['all_string_dnas'], mat['all_labels'], dnabert.tokenizer)\n",
    "\n",
    "# dnabert.model(**dnabert.tokenizer(dna[:10].tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512, return_attention_mask=True)).last_hidden_state[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(dnabert)\n",
    "# reload(dataset)\n",
    "# fine_tune_res = dnabert.finetune(mat, 1050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db67da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=512)\n",
    "all_dna_features_cnn_pca = pca.fit_transform(mat['all_dna_features_cnn_new'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23faf696",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=512)\n",
    "all_image_features_gan_pca = pca.fit_transform(mat['all_image_features_gan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ecc931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FBCOA785-10  ', 'FBCOB090-10  ', 'FBCOJ742-13  ', ...,\n",
       "       'SDP902190-20 ', 'SDP902222-20 ', 'SDP902158-20 '],\n",
       "      shape=(32424,), dtype='<U13')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['all_boldids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "513ccdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [6.956546783447266,\n",
       "  6.956544399261475,\n",
       "  6.956541538238525,\n",
       "  6.956539154052734],\n",
       " 'val_loss': [6.956546783447266,\n",
       "  6.956542491912842,\n",
       "  6.956540107727051,\n",
       "  6.95653772354126],\n",
       " 'val_accuracy': [0.0, 0.0, 0.0, 0.0012368583797155227],\n",
       " 'val_ari': [0.06426883611852384,\n",
       "  0.06573385485768057,\n",
       "  0.0660427554166934,\n",
       "  0.06438161225139968],\n",
       " 'val_nmi': [0.656810221003117,\n",
       "  0.6579820356582857,\n",
       "  0.6574414865281533,\n",
       "  0.6545028017322444]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import models\n",
    "reload(models)\n",
    "from models import AttentionFusion, Predictor, Decoder\n",
    "device = torch.device('cpu')\n",
    "fusion = AttentionFusion(512, 512, 512).to(device)\n",
    "decoder = Decoder(512, 1050).to(device)\n",
    "predictor = Predictor(fusion, decoder).to(device)\n",
    "predictor.fit(all_dna_features_cnn_pca, \n",
    "              all_image_features_gan_pca, \n",
    "              mat['all_labels'].squeeze(), \n",
    "              mat['val_seen_loc'].squeeze(), \n",
    "              mat['train_loc'].squeeze(), \n",
    "              500, \n",
    "              lr=0.0005,\n",
    "              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f6ae599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32424, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dna_features_cnn_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902101d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3, ..., 1048, 1049, 1050], shape=(1050,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mat['all_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4612702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DNAImageDecoder(nn.Module):\n",
    "    def __init__(self, N_dna, N_image, d_model=128, num_heads=4, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Project DNA and image embeddings into same space\n",
    "        self.dna_proj = nn.Linear(N_dna, d_model)\n",
    "        self.img_proj = nn.Linear(N_image, d_model)\n",
    "        \n",
    "        # Self-attention mechanism\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=True)\n",
    "        \n",
    "        # Feed-forward layer after attention\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, dna_emb, img_emb):\n",
    "        \"\"\"\n",
    "        dna_emb: (batch_size, N_dna)\n",
    "        img_emb: (batch_size, N_image)\n",
    "        \"\"\"\n",
    "        # Project to same dimension\n",
    "        dna_token = self.dna_proj(dna_emb).unsqueeze(1)  # (batch, 1, d_model)\n",
    "        img_token = self.img_proj(img_emb).unsqueeze(1)  # (batch, 1, d_model)\n",
    "        \n",
    "        # Sequence: [DNA, Image]\n",
    "        seq = torch.cat([dna_token, img_token], dim=1)  # (batch, 2, d_model)\n",
    "        \n",
    "        # Self-attention\n",
    "        attn_out, _ = self.attn(seq, seq, seq)  # (batch, 2, d_model)\n",
    "        \n",
    "        # Pooling â€” use first token (DNA) or mean-pool\n",
    "        pooled = attn_out.mean(dim=1)  # (batch, d_model)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.ffn(pooled)  # (batch, num_classes)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3cbcbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = nn.MultiheadAttention(768, 4)\n",
    "attn_output, attn_output_weights = (ma(torch.rand(1, 1, 768), torch.rand(1, 1, 768), torch.rand(1, 1, 768)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01b67d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.]]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d50c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna = \"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\"\n",
    "dna_emb = dnabert.model(**dnabert.tokenizer(dna, return_tensors='pt',))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0214d15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load pretrained ViT model\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "imageprocessor = AutoImageProcessor.from_pretrained(model_name)\n",
    "vitmodel = AutoModel.from_pretrained(model_name)\n",
    "vitmodel.eval()\n",
    "\n",
    "# Put model on GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vitmodel.to(device)\n",
    "\n",
    "def get_vit_embedding(image_np, model_name=\"google/vit-base-patch16-224\", device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    inputs = imageprocessor(images=image_np, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = vitmodel(**inputs)\n",
    "    \n",
    "    return outputs.last_hidden_state[:, 0]  # CLS token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b741af4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_emb.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71924dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
