{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hajibagher/insect-classification-deeplearning'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e9b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchviz\n",
    "\n",
    "import vit\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import dnaencoder\n",
    "import pandas as pd\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5954bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mat import mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "791296d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b3c45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3d7bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3234)\n",
      "(1, 3721)\n",
      "(1, 4990)\n",
      "(1, 7440)\n"
     ]
    }
   ],
   "source": [
    "print(mat['val_seen_loc'].shape)\n",
    "print(mat['val_unseen_loc'].shape)\n",
    "print(mat['test_seen_loc'].shape)\n",
    "print(mat['test_unseen_loc'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba81798",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(dnaencoder.evaluate_model(mat, \"amintehrani/dnaencoder-insects-finetuned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"amintehrani/vit-insects-finetuned7\"\n",
    "dict(vit.evaluate_model(mat, model_name, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670983f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13039 3234 3721 4990 7440\n"
     ]
    }
   ],
   "source": [
    "all_images = mat['all_images']\n",
    "all_labels = mat['all_labels'].squeeze()\n",
    "train_indices = mat['train_loc'].squeeze()\n",
    "val_seen_indices = mat['val_seen_loc'].squeeze()\n",
    "val_unseen_indices = mat['val_unseen_loc'].squeeze()\n",
    "test_seen_indices = mat['test_seen_loc'].squeeze()\n",
    "test_unseen_indices = mat['test_unseen_loc'].squeeze()\n",
    "\n",
    "val_indices = np.concatenate((val_seen_indices, val_unseen_indices))\n",
    "test_indices = np.concatenate((test_seen_indices, test_unseen_indices))\n",
    "\n",
    "total_images = all_images.shape[0]\n",
    "print(train_indices.shape[0], val_seen_indices.shape[0], val_unseen_indices.shape[0], test_seen_indices.shape[0], test_unseen_indices.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ff19ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: batch_dna_0.pkl\n",
      "Loading file: batch_dna_1.pkl\n",
      "Loading file: batch_dna_2.pkl\n",
      "Loading file: batch_dna_3.pkl\n",
      "Loading file: batch_dna_4.pkl\n",
      "Loading file: batch_dna_5.pkl\n",
      "Loading file: batch_dna_6.pkl\n",
      "Loading file: batch_dna_7.pkl\n",
      "Loading file: batch_dna_8.pkl\n",
      "Loading file: batch_dna_9.pkl\n",
      "Loading file: batch_dna_10.pkl\n",
      "Loading file: batch_dna_11.pkl\n",
      "Loading file: batch_dna_12.pkl\n",
      "Loading file: batch_dna_13.pkl\n",
      "Loading file: batch_dna_14.pkl\n",
      "Loading file: batch_dna_15.pkl\n",
      "Loading file: batch_dna_16.pkl\n",
      "Loading file: batch_dna_17.pkl\n",
      "Loading file: batch_dna_18.pkl\n",
      "Loading file: batch_dna_19.pkl\n",
      "Loading file: batch_dna_20.pkl\n",
      "Loading file: batch_dna_21.pkl\n",
      "Loading file: batch_dna_22.pkl\n",
      "Loading file: batch_dna_23.pkl\n",
      "Loading file: batch_dna_24.pkl\n",
      "Loading file: batch_dna_25.pkl\n",
      "Loading file: batch_dna_26.pkl\n",
      "Loading file: batch_dna_27.pkl\n",
      "Loading file: batch_dna_28.pkl\n",
      "Loading file: batch_dna_29.pkl\n",
      "Loading file: batch_dna_30.pkl\n",
      "Loading file: batch_dna_31.pkl\n",
      "Loading file: batch_dna_32.pkl\n",
      "Loading file: batch_dna_33.pkl\n",
      "Loading file: batch_dna_34.pkl\n",
      "Loading file: batch_dna_35.pkl\n",
      "Loading file: batch_dna_36.pkl\n",
      "Loading file: batch_dna_37.pkl\n",
      "Loading file: batch_dna_38.pkl\n",
      "Loading file: batch_dna_39.pkl\n",
      "Loading file: batch_dna_40.pkl\n",
      "Loading file: batch_dna_41.pkl\n",
      "Loading file: batch_dna_42.pkl\n",
      "Loading file: batch_dna_43.pkl\n",
      "Loading file: batch_dna_44.pkl\n",
      "Loading file: batch_dna_45.pkl\n",
      "Loading file: batch_dna_46.pkl\n",
      "Loading file: batch_dna_47.pkl\n",
      "Loading file: batch_dna_48.pkl\n",
      "Loading file: batch_dna_49.pkl\n",
      "Loading file: batch_dna_50.pkl\n",
      "Loading file: batch_dna_51.pkl\n",
      "Loading file: batch_dna_52.pkl\n",
      "Loading file: batch_dna_53.pkl\n",
      "Loading file: batch_dna_54.pkl\n",
      "Loading file: batch_dna_55.pkl\n",
      "Loading file: batch_dna_56.pkl\n",
      "Loading file: batch_dna_57.pkl\n",
      "Loading file: batch_dna_58.pkl\n",
      "Loading file: batch_dna_59.pkl\n",
      "Loading file: batch_dna_60.pkl\n",
      "Loading file: batch_dna_61.pkl\n",
      "Loading file: batch_dna_62.pkl\n",
      "Loading file: batch_dna_63.pkl\n",
      "Loading file: batch_dna_64.pkl\n",
      "Loading file: batch_dna_65.pkl\n",
      "Loading file: batch_dna_66.pkl\n",
      "Loading file: batch_dna_67.pkl\n",
      "Loading file: batch_dna_68.pkl\n",
      "Loading file: batch_dna_69.pkl\n",
      "Loading file: batch_dna_70.pkl\n",
      "Loading file: batch_dna_71.pkl\n",
      "Loading file: batch_dna_72.pkl\n",
      "Loading file: batch_dna_73.pkl\n",
      "Loading file: batch_dna_74.pkl\n",
      "Loading file: batch_dna_75.pkl\n",
      "Loading file: batch_dna_76.pkl\n",
      "Loading file: batch_dna_77.pkl\n",
      "Loading file: batch_dna_78.pkl\n",
      "Loading file: batch_dna_79.pkl\n",
      "Loading file: batch_dna_80.pkl\n",
      "Loading file: batch_dna_81.pkl\n",
      "Loading file: batch_dna_82.pkl\n",
      "Loading file: batch_dna_83.pkl\n",
      "Loading file: batch_dna_84.pkl\n",
      "Loading file: batch_dna_85.pkl\n",
      "Loading file: batch_dna_86.pkl\n",
      "Loading file: batch_dna_87.pkl\n",
      "Loading file: batch_dna_88.pkl\n",
      "Loading file: batch_dna_89.pkl\n",
      "Loading file: batch_dna_90.pkl\n",
      "Loading file: batch_dna_91.pkl\n",
      "Loading file: batch_dna_92.pkl\n",
      "Loading file: batch_dna_93.pkl\n",
      "Loading file: batch_dna_94.pkl\n",
      "Loading file: batch_dna_95.pkl\n",
      "Loading file: batch_dna_96.pkl\n",
      "Loading file: batch_dna_97.pkl\n",
      "Loading file: batch_dna_98.pkl\n",
      "Loading file: batch_dna_99.pkl\n",
      "Loading file: batch_dna_100.pkl\n",
      "Loading file: batch_dna_101.pkl\n",
      "Loading file: batch_dna_102.pkl\n",
      "Loading file: batch_dna_103.pkl\n",
      "Loading file: batch_dna_104.pkl\n",
      "Loading file: batch_dna_105.pkl\n",
      "Loading file: batch_dna_106.pkl\n",
      "Loading file: batch_dna_107.pkl\n",
      "Loading file: batch_dna_108.pkl\n",
      "Loading file: batch_dna_109.pkl\n",
      "Loading file: batch_dna_110.pkl\n",
      "Loading file: batch_dna_111.pkl\n",
      "Loading file: batch_dna_112.pkl\n",
      "Loading file: batch_dna_113.pkl\n",
      "Loading file: batch_dna_114.pkl\n",
      "Loading file: batch_dna_115.pkl\n",
      "Loading file: batch_dna_116.pkl\n",
      "Loading file: batch_dna_117.pkl\n",
      "Loading file: batch_dna_118.pkl\n",
      "Loading file: batch_dna_119.pkl\n",
      "Loading file: batch_dna_120.pkl\n",
      "Loading file: batch_dna_121.pkl\n",
      "Loading file: batch_dna_122.pkl\n",
      "Loading file: batch_dna_123.pkl\n",
      "Loading file: batch_dna_124.pkl\n",
      "Loading file: batch_dna_125.pkl\n",
      "Loading file: batch_dna_126.pkl\n",
      "Loading file: batch_dna_127.pkl\n",
      "Loading file: batch_dna_128.pkl\n",
      "Loading file: batch_dna_129.pkl\n",
      "Loading file: batch_dna_130.pkl\n",
      "Loading file: batch_dna_131.pkl\n",
      "Loading file: batch_dna_132.pkl\n",
      "Loading file: batch_dna_133.pkl\n",
      "Loading file: batch_dna_134.pkl\n",
      "Loading file: batch_dna_135.pkl\n",
      "Loading file: batch_dna_136.pkl\n",
      "Loading file: batch_dna_137.pkl\n",
      "Loading file: batch_dna_138.pkl\n",
      "Loading file: batch_dna_139.pkl\n",
      "Loading file: batch_dna_140.pkl\n",
      "Loading file: batch_dna_141.pkl\n",
      "Loading file: batch_dna_142.pkl\n",
      "Loading file: batch_dna_143.pkl\n",
      "Loading file: batch_dna_144.pkl\n",
      "Loading file: batch_dna_145.pkl\n",
      "Loading file: batch_dna_146.pkl\n",
      "Loading file: batch_dna_147.pkl\n",
      "Loading file: batch_dna_148.pkl\n",
      "Loading file: batch_dna_149.pkl\n",
      "Loading file: batch_dna_150.pkl\n",
      "Loading file: batch_dna_151.pkl\n",
      "Loading file: batch_dna_152.pkl\n",
      "Loading file: batch_dna_153.pkl\n",
      "Loading file: batch_dna_154.pkl\n",
      "Loading file: batch_dna_155.pkl\n",
      "Loading file: batch_dna_156.pkl\n",
      "Loading file: batch_dna_157.pkl\n",
      "Loading file: batch_dna_158.pkl\n",
      "Loading file: batch_dna_159.pkl\n",
      "Loading file: batch_dna_160.pkl\n",
      "Loading file: batch_dna_161.pkl\n",
      "Loading file: batch_dna_162.pkl\n",
      "Loading file: batch_dna_163.pkl\n",
      "Loading file: batch_dna_164.pkl\n",
      "Loading file: batch_dna_165.pkl\n",
      "Loading file: batch_dna_166.pkl\n",
      "Loading file: batch_dna_167.pkl\n",
      "Loading file: batch_dna_168.pkl\n",
      "Loading file: batch_dna_169.pkl\n",
      "Loading file: batch_dna_170.pkl\n",
      "Loading file: batch_dna_171.pkl\n",
      "Loading file: batch_dna_172.pkl\n",
      "Loading file: batch_dna_173.pkl\n",
      "Loading file: batch_dna_174.pkl\n",
      "Loading file: batch_dna_175.pkl\n",
      "Loading file: batch_dna_176.pkl\n",
      "Loading file: batch_dna_177.pkl\n",
      "Loading file: batch_dna_178.pkl\n",
      "Loading file: batch_dna_179.pkl\n",
      "Loading file: batch_dna_180.pkl\n",
      "Loading file: batch_dna_181.pkl\n",
      "Loading file: batch_dna_182.pkl\n",
      "Loading file: batch_dna_183.pkl\n",
      "Loading file: batch_dna_184.pkl\n",
      "Loading file: batch_dna_185.pkl\n",
      "Loading file: batch_dna_186.pkl\n",
      "Loading file: batch_dna_187.pkl\n",
      "Loading file: batch_dna_188.pkl\n",
      "Loading file: batch_dna_189.pkl\n",
      "Loading file: batch_dna_190.pkl\n",
      "Loading file: batch_dna_191.pkl\n",
      "Loading file: batch_dna_192.pkl\n",
      "Loading file: batch_dna_193.pkl\n",
      "Loading file: batch_dna_194.pkl\n",
      "Loading file: batch_dna_195.pkl\n",
      "Loading file: batch_dna_196.pkl\n",
      "Loading file: batch_dna_197.pkl\n",
      "Loading file: batch_dna_198.pkl\n",
      "Loading file: batch_dna_199.pkl\n",
      "Loading file: batch_dna_200.pkl\n",
      "Loading file: batch_dna_201.pkl\n",
      "Loading file: batch_dna_202.pkl\n",
      "Loading file: batch_dna_203.pkl\n",
      "Loading file: batch_dna_204.pkl\n",
      "Loading file: batch_dna_205.pkl\n",
      "Loading file: batch_dna_206.pkl\n",
      "Loading file: batch_dna_207.pkl\n",
      "Loading file: batch_dna_208.pkl\n",
      "Loading file: batch_dna_209.pkl\n",
      "Loading file: batch_dna_210.pkl\n",
      "Loading file: batch_dna_211.pkl\n",
      "Loading file: batch_dna_212.pkl\n",
      "Loading file: batch_dna_213.pkl\n",
      "Loading file: batch_dna_214.pkl\n",
      "Loading file: batch_dna_215.pkl\n",
      "Loading file: batch_dna_216.pkl\n",
      "Loading file: batch_dna_217.pkl\n",
      "Loading file: batch_dna_218.pkl\n",
      "Loading file: batch_dna_219.pkl\n",
      "Loading file: batch_dna_220.pkl\n",
      "Loading file: batch_dna_221.pkl\n",
      "Loading file: batch_dna_222.pkl\n",
      "Loading file: batch_dna_223.pkl\n",
      "Loading file: batch_dna_224.pkl\n",
      "Loading file: batch_dna_225.pkl\n",
      "Loading file: batch_dna_226.pkl\n",
      "Loading file: batch_dna_227.pkl\n",
      "Loading file: batch_dna_228.pkl\n",
      "Loading file: batch_dna_229.pkl\n",
      "Loading file: batch_dna_230.pkl\n",
      "Loading file: batch_dna_231.pkl\n",
      "Loading file: batch_dna_232.pkl\n",
      "Loading file: batch_dna_233.pkl\n",
      "Loading file: batch_dna_234.pkl\n",
      "Loading file: batch_dna_235.pkl\n",
      "Loading file: batch_dna_236.pkl\n",
      "Loading file: batch_dna_237.pkl\n",
      "Loading file: batch_dna_238.pkl\n",
      "Loading file: batch_dna_239.pkl\n",
      "Loading file: batch_dna_240.pkl\n",
      "Loading file: batch_dna_241.pkl\n",
      "Loading file: batch_dna_242.pkl\n",
      "Loading file: batch_dna_243.pkl\n",
      "Loading file: batch_dna_244.pkl\n",
      "Loading file: batch_dna_245.pkl\n",
      "Loading file: batch_dna_246.pkl\n",
      "Loading file: batch_dna_247.pkl\n",
      "Loading file: batch_dna_248.pkl\n",
      "Loading file: batch_dna_249.pkl\n",
      "Loading file: batch_dna_250.pkl\n",
      "Loading file: batch_dna_251.pkl\n",
      "Loading file: batch_dna_252.pkl\n",
      "Loading file: batch_dna_253.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: batch_img_0.pkl\n",
      "Loading file: batch_img_1.pkl\n",
      "Loading file: batch_img_2.pkl\n",
      "Loading file: batch_img_3.pkl\n",
      "Loading file: batch_img_4.pkl\n",
      "Loading file: batch_img_5.pkl\n",
      "Loading file: batch_img_6.pkl\n",
      "Loading file: batch_img_7.pkl\n",
      "Loading file: batch_img_8.pkl\n",
      "Loading file: batch_img_9.pkl\n",
      "Loading file: batch_img_10.pkl\n",
      "Loading file: batch_img_11.pkl\n",
      "Loading file: batch_img_12.pkl\n",
      "Loading file: batch_img_13.pkl\n",
      "Loading file: batch_img_14.pkl\n",
      "Loading file: batch_img_15.pkl\n",
      "Loading file: batch_img_16.pkl\n",
      "Loading file: batch_img_17.pkl\n",
      "Loading file: batch_img_18.pkl\n",
      "Loading file: batch_img_19.pkl\n",
      "Loading file: batch_img_20.pkl\n",
      "Loading file: batch_img_21.pkl\n",
      "Loading file: batch_img_22.pkl\n",
      "Loading file: batch_img_23.pkl\n",
      "Loading file: batch_img_24.pkl\n",
      "Loading file: batch_img_25.pkl\n",
      "Loading file: batch_img_26.pkl\n",
      "Loading file: batch_img_27.pkl\n",
      "Loading file: batch_img_28.pkl\n",
      "Loading file: batch_img_29.pkl\n",
      "Loading file: batch_img_30.pkl\n",
      "Loading file: batch_img_31.pkl\n",
      "Loading file: batch_img_32.pkl\n",
      "Loading file: batch_img_33.pkl\n",
      "Loading file: batch_img_34.pkl\n",
      "Loading file: batch_img_35.pkl\n",
      "Loading file: batch_img_36.pkl\n",
      "Loading file: batch_img_37.pkl\n",
      "Loading file: batch_img_38.pkl\n",
      "Loading file: batch_img_39.pkl\n",
      "Loading file: batch_img_40.pkl\n",
      "Loading file: batch_img_41.pkl\n",
      "Loading file: batch_img_42.pkl\n",
      "Loading file: batch_img_43.pkl\n",
      "Loading file: batch_img_44.pkl\n",
      "Loading file: batch_img_45.pkl\n",
      "Loading file: batch_img_46.pkl\n",
      "Loading file: batch_img_47.pkl\n",
      "Loading file: batch_img_48.pkl\n",
      "Loading file: batch_img_49.pkl\n",
      "Loading file: batch_img_50.pkl\n",
      "Loading file: batch_img_51.pkl\n",
      "Loading file: batch_img_52.pkl\n",
      "Loading file: batch_img_53.pkl\n",
      "Loading file: batch_img_54.pkl\n",
      "Loading file: batch_img_55.pkl\n",
      "Loading file: batch_img_56.pkl\n",
      "Loading file: batch_img_57.pkl\n",
      "Loading file: batch_img_58.pkl\n",
      "Loading file: batch_img_59.pkl\n",
      "Loading file: batch_img_60.pkl\n",
      "Loading file: batch_img_61.pkl\n",
      "Loading file: batch_img_62.pkl\n",
      "Loading file: batch_img_63.pkl\n"
     ]
    }
   ],
   "source": [
    "from multimodal_dataset import MultiModalDataset\n",
    "from load_embeddings import load_dna_embeddings, load_img_embeddings\n",
    "\n",
    "all_dna_features = load_dna_embeddings()\n",
    "all_image_features = load_img_embeddings()\n",
    "\n",
    "all_dna_len = list(map(lambda s: len(s.strip()), mat['all_string_dnas']))\n",
    "dna_str_len_mapping: dict[int,int] = {}\n",
    "\n",
    "def dna_str_len_to_int(s_len):\n",
    "    if s_len not in dna_str_len_mapping:\n",
    "        dna_str_len_mapping[s_len] = len(dna_str_len_mapping)\n",
    "    return dna_str_len_mapping[s_len]\n",
    "\n",
    "# def all_dna_len_token():\n",
    "#     return list(map(dna_str_len_to_int, all_dna_len))\n",
    "\n",
    "all_dna_len_tokens = list(map(dna_str_len_to_int, all_dna_len))\n",
    "all_dna_len_tokens = np.array(all_dna_len_tokens, dtype=np.int64)\n",
    "\n",
    "species2genus = mat['species2genus']-1\n",
    "\n",
    "\n",
    "genus_species = dict()\n",
    "max_specie_in_genus = 0\n",
    "for genus_id, genus in pd.DataFrame(species2genus, columns=['genus']).groupby('genus'):\n",
    "    specie_indices = genus.index.tolist()\n",
    "    genus_species[genus_id] = specie_indices\n",
    "    if len(specie_indices) > max_specie_in_genus:\n",
    "        max_specie_in_genus = len(specie_indices)\n",
    "\n",
    "import multimodal_dataset\n",
    "reload(multimodal_dataset)\n",
    "from multimodal_dataset import MultiModalDataset\n",
    "datasets = {\n",
    "    indicies_type:MultiModalDataset(\n",
    "        mat['all_string_dnas'][(inds:=mat[indicies_type].flatten())],\n",
    "        mat['all_images'][inds],\n",
    "        np.transpose(mat['all_labels'], (1,0))[inds],\n",
    "        dna_str_len_mapping,\n",
    "        species2genus,\n",
    "        genus_species,\n",
    "        None,\n",
    "        None,\n",
    "        dna_embeddings=all_dna_features[inds],\n",
    "        img_embeddings=all_image_features[inds]\n",
    "    )\n",
    "    for indicies_type in [\"val_seen_loc\", \"val_unseen_loc\", \"test_seen_loc\", \"test_unseen_loc\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "557fe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate:\n",
    "import models\n",
    "reload(models)\n",
    "from models import AttentionFusion, GenusClassifier, LocalSpecieClassfier, MainClassifier, multimodal_collector\n",
    "\n",
    "fusion_embedder = AttentionFusion(dna_dim=512,img_dim=768,dna_len_dim=32, fused_dim=258, proj_dna_dim=128-32, proj_img_dim=128, dropout=0.2)\n",
    "# print(\"fusion_embedder\", fusion_embedder._config)\n",
    "# print(\"Fusion model created. fused dim: \", fusion_embedder.fused_dim)\n",
    "genus_classifier = GenusClassifier(fusion_embedder.fused_dim,dropout=0.1, dna_len_dim=32)\n",
    "local_specie_classifier = LocalSpecieClassfier(fusion_embedder.fused_dim,reduced_fused_dim=128, specie_decoder_hidden_dim=256, dropout=0.1,dna_len_dim=32)\n",
    "\n",
    "# main_classifier = MainClassifier(mat['species2genus'], genus_species, None, None, fusion_embedder, genus_classifier,local_specie_classifier,alpha=2, beta=0, theta=0,).to(device)\n",
    "main_classifier = MainClassifier.load_model(\"./results_20250827T234918-final\", mat['species2genus'], genus_species).to(device)\n",
    "\n",
    "assert main_classifier.fusion_embedder._config == fusion_embedder._config\n",
    "assert main_classifier.genus_classifier._config == genus_classifier._config\n",
    "assert main_classifier.local_specie_classifier._config == local_specie_classifier._config\n",
    "# print(main_classifier)\n",
    "dict(main_classifier.evaluate(datasets))\n",
    "\n",
    "\n",
    "# print(main_classifier)\n",
    "# main_classifier.load_model(\"results_20250819T030148-final\")\n",
    "# train_indices = (mat['train_loc'] - 1).flatten()  # Get train indices\n",
    "# train_dataset = MultiModalDataset(mat['all_string_dnas'][train_indices], mat['all_images'][train_indices], np.transpose(mat['all_labels'], (1,0))[train_indices], dna_str_len_mapping, species2genus, genus_species, None, None, dna_embeddings=all_dna_features[train_indices], img_embeddings=all_image_features[train_indices])\n",
    "# main_classifier.fit(\n",
    "#     train_dataset,\n",
    "#     None,\n",
    "#     batch_size=64,\n",
    "#     epochs=1,\n",
    "#     eval_steps=200,\n",
    "#     save_steps=400,\n",
    "#     lr=1e-3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea82dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# main_classifier2 = MainClassifier.load_modelV2(\"./model_trained_v2_20250828T164138-final\", mat['species2genus'], genus_species).to(device)\n",
    "\n",
    "# pprint(dict(main_classifier2.evaluate(datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1392e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_classifier2 = MainClassifier.load_model(\"./model_trained_20250828T200842-final\", mat['species2genus'], genus_species).to(device)\n",
    "\n",
    "# pprint(dict(main_classifier2.evaluate(datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3441d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model config: {'fusion_embedder': {'dna_dim': 512, 'img_dim': 768, 'fused_dim': 256, 'dna_len_dim': 32, 'num_distinct_dna_len': 120, 'proj_dna_dim': 96, 'proj_img_dim': 128, 'dropout': 0.2}, 'genus_classifier': {'fused_dim': 256, 'hidden_dim': 744, 'genus_n_classes': 372, 'dropout': 0.2, 'dna_len_dim': 32}, 'local_specie_classifier': {'fused_dim': 256, 'genus_n_classes': 372, 'reduced_fused_dim': 256, 'max_specie_in_genus': 23, 'genus_embedding_dim': 64, 'specie_decoder_hidden_dim': 256, 'dropout': 0.2, 'dna_len_dim': 32}}\n",
      "Loaded model state: <All keys matched successfully>\n",
      "Evaluating val_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating val_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_seen_loc': {'eval_accuracy': 0.5783567134268537,\n",
      "                   'eval_loss': 5.358677387237549,\n",
      "                   'eval_runtime': 2.4772,\n",
      "                   'eval_samples_per_second': 2014.343,\n",
      "                   'eval_steps_per_second': 15.743},\n",
      " 'test_unseen_loc': {'eval_accuracy': 0.37446236559139784,\n",
      "                     'eval_loss': 5.560892581939697,\n",
      "                     'eval_runtime': 3.2243,\n",
      "                     'eval_samples_per_second': 2307.49,\n",
      "                     'eval_steps_per_second': 18.299},\n",
      " 'val_seen_loc': {'eval_accuracy': 0.6014223871366728,\n",
      "                  'eval_loss': 5.335085391998291,\n",
      "                  'eval_runtime': 1.475,\n",
      "                  'eval_samples_per_second': 2192.557,\n",
      "                  'eval_steps_per_second': 17.627},\n",
      " 'val_unseen_loc': {'eval_accuracy': 0.4254232733136254,\n",
      "                    'eval_loss': 5.513214588165283,\n",
      "                    'eval_runtime': 1.5053,\n",
      "                    'eval_samples_per_second': 2472.013,\n",
      "                    'eval_steps_per_second': 19.93}}\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "reload(models)\n",
    "from models import MainClassifier\n",
    "\n",
    "\n",
    "main_classifier2 = MainClassifier.load_model(\"model_trained_20250828T221231_freezegenus-final\", mat['species2genus'], genus_species).to(device)\n",
    "\n",
    "pprint(dict(main_classifier2.evaluate(datasets, only_genus=True)))\n",
    "# pprint(dict(main_classifier2.evaluate_genus(datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e776e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3bbf501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model config: {'fusion_embedder': {'dna_dim': 512, 'img_dim': 768, 'fused_dim': 256, 'dna_len_dim': 32, 'num_distinct_dna_len': 120, 'proj_dna_dim': 96, 'proj_img_dim': 128, 'dropout': 0.2}, 'genus_classifier': {'fused_dim': 256, 'hidden_dim': 744, 'genus_n_classes': 372, 'dropout': 0.2, 'dna_len_dim': 32}, 'local_specie_classifier': {'fused_dim': 256, 'genus_n_classes': 372, 'reduced_fused_dim': 256, 'max_specie_in_genus': 23, 'genus_embedding_dim': 64, 'specie_decoder_hidden_dim': 256, 'dropout': 0.2, 'dna_len_dim': 32}}\n",
      "Loaded model state: <All keys matched successfully>\n",
      "Evaluating val_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating val_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_seen_loc': {'eval_accuracy': 0.38336673346693384,\n",
      "                   'eval_loss': 5.543541431427002,\n",
      "                   'eval_runtime': 1.2287,\n",
      "                   'eval_samples_per_second': 4061.207,\n",
      "                   'eval_steps_per_second': 31.741},\n",
      " 'test_unseen_loc': {'eval_accuracy': 0.3565860215053763,\n",
      "                     'eval_loss': 5.578000068664551,\n",
      "                     'eval_runtime': 1.8431,\n",
      "                     'eval_samples_per_second': 4036.59,\n",
      "                     'eval_steps_per_second': 32.011},\n",
      " 'val_seen_loc': {'eval_accuracy': 0.37353123067408783,\n",
      "                  'eval_loss': 5.551101207733154,\n",
      "                  'eval_runtime': 0.8774,\n",
      "                  'eval_samples_per_second': 3685.933,\n",
      "                  'eval_steps_per_second': 29.633},\n",
      " 'val_unseen_loc': {'eval_accuracy': 0.3372749260951357,\n",
      "                    'eval_loss': 5.6045823097229,\n",
      "                    'eval_runtime': 0.9327,\n",
      "                    'eval_samples_per_second': 3989.584,\n",
      "                    'eval_steps_per_second': 32.165}}\n",
      "Evaluating val_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating val_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_seen_loc': {'eval_accuracy': 0.30801603206412825,\n",
      "                   'eval_loss': 29.34588623046875,\n",
      "                   'eval_runtime': 3.2928,\n",
      "                   'eval_samples_per_second': 1515.412,\n",
      "                   'eval_steps_per_second': 11.844},\n",
      " 'test_unseen_loc': {'eval_accuracy': 0.014381720430107527,\n",
      "                     'eval_loss': 36.8821907043457,\n",
      "                     'eval_runtime': 4.7767,\n",
      "                     'eval_samples_per_second': 1557.558,\n",
      "                     'eval_steps_per_second': 12.352},\n",
      " 'val_seen_loc': {'eval_accuracy': 0.36023500309214596,\n",
      "                  'eval_loss': 28.06710433959961,\n",
      "                  'eval_runtime': 2.0338,\n",
      "                  'eval_samples_per_second': 1590.144,\n",
      "                  'eval_steps_per_second': 12.784},\n",
      " 'val_unseen_loc': {'eval_accuracy': 0.009674818597151304,\n",
      "                    'eval_loss': 36.51240539550781,\n",
      "                    'eval_runtime': 2.5073,\n",
      "                    'eval_samples_per_second': 1484.041,\n",
      "                    'eval_steps_per_second': 11.965}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import models\n",
    "reload(models)\n",
    "from models import MainClassifier\n",
    "\n",
    "\n",
    "main_classifier2 = MainClassifier.load_model(\"./model_trained_20250828T224831-final\", mat['species2genus'], genus_species).to(device)\n",
    "\n",
    "pprint(dict(main_classifier2.evaluate(datasets, only_genus=True)))\n",
    "pprint(dict(main_classifier2.evaluate(datasets, only_genus=False)))\n",
    "# pprint(dict(main_classifier2.evaluate_genus(datasets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bca4057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model config: {'fusion_embedder': {'dna_dim': 512, 'img_dim': 768, 'fused_dim': 256, 'dna_len_dim': 32, 'num_distinct_dna_len': 120, 'proj_dna_dim': 96, 'proj_img_dim': 128, 'dropout': 0.2}, 'genus_classifier': {'fused_dim': 256, 'hidden_dim': 744, 'genus_n_classes': 372, 'dropout': 0.2, 'dna_len_dim': 32}, 'local_specie_classifier': {'fused_dim': 256, 'genus_n_classes': 372, 'reduced_fused_dim': 256, 'max_specie_in_genus': 23, 'genus_embedding_dim': 64, 'specie_decoder_hidden_dim': 256, 'dropout': 0.2, 'dna_len_dim': 32}}\n",
      "Loaded model state: <All keys matched successfully>\n",
      "Evaluating val_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating val_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_seen_loc': {'eval_accuracy': 0.4803607214428858,\n",
      "                   'eval_loss': 5.446527481079102,\n",
      "                   'eval_runtime': 1.2508,\n",
      "                   'eval_samples_per_second': 3989.557,\n",
      "                   'eval_steps_per_second': 31.181},\n",
      " 'test_unseen_loc': {'eval_accuracy': 0.46411290322580645,\n",
      "                     'eval_loss': 5.473125457763672,\n",
      "                     'eval_runtime': 1.8262,\n",
      "                     'eval_samples_per_second': 4074.114,\n",
      "                     'eval_steps_per_second': 32.308},\n",
      " 'val_seen_loc': {'eval_accuracy': 0.4839208410636982,\n",
      "                  'eval_loss': 5.442411422729492,\n",
      "                  'eval_runtime': 0.8147,\n",
      "                  'eval_samples_per_second': 3969.497,\n",
      "                  'eval_steps_per_second': 31.913},\n",
      " 'val_unseen_loc': {'eval_accuracy': 0.49529696318194033,\n",
      "                    'eval_loss': 5.439754962921143,\n",
      "                    'eval_runtime': 1.2905,\n",
      "                    'eval_samples_per_second': 2883.406,\n",
      "                    'eval_steps_per_second': 23.247}}\n",
      "Evaluating val_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating val_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test_unseen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_seen_loc': {'eval_accuracy': 0.3721442885771543,\n",
      "                   'eval_loss': 27.76049041748047,\n",
      "                   'eval_runtime': 3.2055,\n",
      "                   'eval_samples_per_second': 1556.715,\n",
      "                   'eval_steps_per_second': 12.167},\n",
      " 'test_unseen_loc': {'eval_accuracy': 0.018951612903225806,\n",
      "                     'eval_loss': 36.282920837402344,\n",
      "                     'eval_runtime': 4.8968,\n",
      "                     'eval_samples_per_second': 1519.354,\n",
      "                     'eval_steps_per_second': 12.049},\n",
      " 'val_seen_loc': {'eval_accuracy': 0.4678416821273964,\n",
      "                  'eval_loss': 25.730167388916016,\n",
      "                  'eval_runtime': 2.1181,\n",
      "                  'eval_samples_per_second': 1526.85,\n",
      "                  'eval_steps_per_second': 12.275},\n",
      " 'val_unseen_loc': {'eval_accuracy': 0.02069336199946251,\n",
      "                    'eval_loss': 35.923255920410156,\n",
      "                    'eval_runtime': 2.3274,\n",
      "                    'eval_samples_per_second': 1598.807,\n",
      "                    'eval_steps_per_second': 12.89}}\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "reload(models)\n",
    "from models import MainClassifier\n",
    "\n",
    "\n",
    "main_classifier2 = MainClassifier.load_model(\"model_trained_20250828T224022-final\", mat['species2genus'], genus_species).to(device)\n",
    "\n",
    "pprint(dict(main_classifier2.evaluate(datasets, only_genus=True)))\n",
    "pprint(dict(main_classifier2.evaluate(datasets, only_genus=False)))\n",
    "# pprint(dict(main_classifier2.evaluate_genus(datasets)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
