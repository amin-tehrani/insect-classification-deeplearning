{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f4e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hajibagher/insect-classification-deeplearning'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9e9b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchviz\n",
    "\n",
    "import vit\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import dnaencoder\n",
    "import pandas as pd\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec5954bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mat import mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "791296d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49b3c45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ba81798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: amintehrani/dnaencoder-insects-finetuned\n",
      "Number of classes: 1051\n",
      "Validation samples: 3234\n",
      "Evaluating validation dataset...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 04:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating validation dataset...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/117 04:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/156 06:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test unseen evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='233' max='233' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [233/233 09:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_seen': {'eval_loss': 3.958054304122925,\n",
       "  'eval_model_preparation_time': 0.0052,\n",
       "  'eval_accuracy': 0.7878787878787878,\n",
       "  'eval_runtime': 245.3919,\n",
       "  'eval_samples_per_second': 13.179,\n",
       "  'eval_steps_per_second': 0.416},\n",
       " 'val_unseen': {'eval_loss': 7.709295749664307,\n",
       "  'eval_model_preparation_time': 0.0056,\n",
       "  'eval_accuracy': 0.0,\n",
       "  'eval_runtime': 282.3414,\n",
       "  'eval_samples_per_second': 13.179,\n",
       "  'eval_steps_per_second': 0.414},\n",
       " 'test_seen': {'eval_loss': 4.644564151763916,\n",
       "  'eval_model_preparation_time': 0.0054,\n",
       "  'eval_accuracy': 0.643687374749499,\n",
       "  'eval_runtime': 378.7899,\n",
       "  'eval_samples_per_second': 13.174,\n",
       "  'eval_steps_per_second': 0.412},\n",
       " 'test_unseen': {'eval_loss': 7.724428653717041,\n",
       "  'eval_model_preparation_time': 0.0053,\n",
       "  'eval_accuracy': 0.0,\n",
       "  'eval_runtime': 564.6694,\n",
       "  'eval_samples_per_second': 13.176,\n",
       "  'eval_steps_per_second': 0.413}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(dnaencoder.evaluate_model(mat, \"amintehrani/dnaencoder-insects-finetuned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb0a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102/102 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/117 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/156 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='233' max='233' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [233/233 00:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('val_seen_indices',\n",
       "  {'eval_loss': 0.82353675365448,\n",
       "   'eval_model_preparation_time': 0.0026,\n",
       "   'eval_accuracy': 0.8528138528138528,\n",
       "   'eval_runtime': 16.6445,\n",
       "   'eval_samples_per_second': 194.299,\n",
       "   'eval_steps_per_second': 6.128}),\n",
       " ('val_unseen_indices',\n",
       "  {'eval_loss': 10.643092155456543,\n",
       "   'eval_model_preparation_time': 0.003,\n",
       "   'eval_accuracy': 0.013705993012631014,\n",
       "   'eval_runtime': 18.0735,\n",
       "   'eval_samples_per_second': 205.882,\n",
       "   'eval_steps_per_second': 6.474}),\n",
       " ('test_seen_indices',\n",
       "  {'eval_loss': 2.636476755142212,\n",
       "   'eval_model_preparation_time': 0.0029,\n",
       "   'eval_accuracy': 0.6951903807615231,\n",
       "   'eval_runtime': 24.294,\n",
       "   'eval_samples_per_second': 205.401,\n",
       "   'eval_steps_per_second': 6.421}),\n",
       " ('test_unseen_indices',\n",
       "  {'eval_loss': 10.732027053833008,\n",
       "   'eval_model_preparation_time': 0.0029,\n",
       "   'eval_accuracy': 0.01599462365591398,\n",
       "   'eval_runtime': 36.441,\n",
       "   'eval_samples_per_second': 204.166,\n",
       "   'eval_steps_per_second': 6.394})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"amintehrani/vit-insects-finetuned7\"\n",
    "dict(vit.evaluate_model(mat, model_name, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "670983f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13039 3234 3721 4990 7440\n"
     ]
    }
   ],
   "source": [
    "all_images = mat['all_images']\n",
    "all_labels = mat['all_labels'].squeeze()\n",
    "train_indices = mat['train_loc'].squeeze()\n",
    "val_seen_indices = mat['val_seen_loc'].squeeze()\n",
    "val_unseen_indices = mat['val_unseen_loc'].squeeze()\n",
    "test_seen_indices = mat['test_seen_loc'].squeeze()\n",
    "test_unseen_indices = mat['test_unseen_loc'].squeeze()\n",
    "\n",
    "val_indices = np.concatenate((val_seen_indices, val_unseen_indices))\n",
    "test_indices = np.concatenate((test_seen_indices, test_unseen_indices))\n",
    "\n",
    "total_images = all_images.shape[0]\n",
    "print(train_indices.shape[0], val_seen_indices.shape[0], val_unseen_indices.shape[0], test_seen_indices.shape[0], test_unseen_indices.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a7e518c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3234)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"val_seen_loc\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91ff19ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: batch_dna_0.pkl\n",
      "Loading file: batch_dna_1.pkl\n",
      "Loading file: batch_dna_2.pkl\n",
      "Loading file: batch_dna_3.pkl\n",
      "Loading file: batch_dna_4.pkl\n",
      "Loading file: batch_dna_5.pkl\n",
      "Loading file: batch_dna_6.pkl\n",
      "Loading file: batch_dna_7.pkl\n",
      "Loading file: batch_dna_8.pkl\n",
      "Loading file: batch_dna_9.pkl\n",
      "Loading file: batch_dna_10.pkl\n",
      "Loading file: batch_dna_11.pkl\n",
      "Loading file: batch_dna_12.pkl\n",
      "Loading file: batch_dna_13.pkl\n",
      "Loading file: batch_dna_14.pkl\n",
      "Loading file: batch_dna_15.pkl\n",
      "Loading file: batch_dna_16.pkl\n",
      "Loading file: batch_dna_17.pkl\n",
      "Loading file: batch_dna_18.pkl\n",
      "Loading file: batch_dna_19.pkl\n",
      "Loading file: batch_dna_20.pkl\n",
      "Loading file: batch_dna_21.pkl\n",
      "Loading file: batch_dna_22.pkl\n",
      "Loading file: batch_dna_23.pkl\n",
      "Loading file: batch_dna_24.pkl\n",
      "Loading file: batch_dna_25.pkl\n",
      "Loading file: batch_dna_26.pkl\n",
      "Loading file: batch_dna_27.pkl\n",
      "Loading file: batch_dna_28.pkl\n",
      "Loading file: batch_dna_29.pkl\n",
      "Loading file: batch_dna_30.pkl\n",
      "Loading file: batch_dna_31.pkl\n",
      "Loading file: batch_dna_32.pkl\n",
      "Loading file: batch_dna_33.pkl\n",
      "Loading file: batch_dna_34.pkl\n",
      "Loading file: batch_dna_35.pkl\n",
      "Loading file: batch_dna_36.pkl\n",
      "Loading file: batch_dna_37.pkl\n",
      "Loading file: batch_dna_38.pkl\n",
      "Loading file: batch_dna_39.pkl\n",
      "Loading file: batch_dna_40.pkl\n",
      "Loading file: batch_dna_41.pkl\n",
      "Loading file: batch_dna_42.pkl\n",
      "Loading file: batch_dna_43.pkl\n",
      "Loading file: batch_dna_44.pkl\n",
      "Loading file: batch_dna_45.pkl\n",
      "Loading file: batch_dna_46.pkl\n",
      "Loading file: batch_dna_47.pkl\n",
      "Loading file: batch_dna_48.pkl\n",
      "Loading file: batch_dna_49.pkl\n",
      "Loading file: batch_dna_50.pkl\n",
      "Loading file: batch_dna_51.pkl\n",
      "Loading file: batch_dna_52.pkl\n",
      "Loading file: batch_dna_53.pkl\n",
      "Loading file: batch_dna_54.pkl\n",
      "Loading file: batch_dna_55.pkl\n",
      "Loading file: batch_dna_56.pkl\n",
      "Loading file: batch_dna_57.pkl\n",
      "Loading file: batch_dna_58.pkl\n",
      "Loading file: batch_dna_59.pkl\n",
      "Loading file: batch_dna_60.pkl\n",
      "Loading file: batch_dna_61.pkl\n",
      "Loading file: batch_dna_62.pkl\n",
      "Loading file: batch_dna_63.pkl\n",
      "Loading file: batch_dna_64.pkl\n",
      "Loading file: batch_dna_65.pkl\n",
      "Loading file: batch_dna_66.pkl\n",
      "Loading file: batch_dna_67.pkl\n",
      "Loading file: batch_dna_68.pkl\n",
      "Loading file: batch_dna_69.pkl\n",
      "Loading file: batch_dna_70.pkl\n",
      "Loading file: batch_dna_71.pkl\n",
      "Loading file: batch_dna_72.pkl\n",
      "Loading file: batch_dna_73.pkl\n",
      "Loading file: batch_dna_74.pkl\n",
      "Loading file: batch_dna_75.pkl\n",
      "Loading file: batch_dna_76.pkl\n",
      "Loading file: batch_dna_77.pkl\n",
      "Loading file: batch_dna_78.pkl\n",
      "Loading file: batch_dna_79.pkl\n",
      "Loading file: batch_dna_80.pkl\n",
      "Loading file: batch_dna_81.pkl\n",
      "Loading file: batch_dna_82.pkl\n",
      "Loading file: batch_dna_83.pkl\n",
      "Loading file: batch_dna_84.pkl\n",
      "Loading file: batch_dna_85.pkl\n",
      "Loading file: batch_dna_86.pkl\n",
      "Loading file: batch_dna_87.pkl\n",
      "Loading file: batch_dna_88.pkl\n",
      "Loading file: batch_dna_89.pkl\n",
      "Loading file: batch_dna_90.pkl\n",
      "Loading file: batch_dna_91.pkl\n",
      "Loading file: batch_dna_92.pkl\n",
      "Loading file: batch_dna_93.pkl\n",
      "Loading file: batch_dna_94.pkl\n",
      "Loading file: batch_dna_95.pkl\n",
      "Loading file: batch_dna_96.pkl\n",
      "Loading file: batch_dna_97.pkl\n",
      "Loading file: batch_dna_98.pkl\n",
      "Loading file: batch_dna_99.pkl\n",
      "Loading file: batch_dna_100.pkl\n",
      "Loading file: batch_dna_101.pkl\n",
      "Loading file: batch_dna_102.pkl\n",
      "Loading file: batch_dna_103.pkl\n",
      "Loading file: batch_dna_104.pkl\n",
      "Loading file: batch_dna_105.pkl\n",
      "Loading file: batch_dna_106.pkl\n",
      "Loading file: batch_dna_107.pkl\n",
      "Loading file: batch_dna_108.pkl\n",
      "Loading file: batch_dna_109.pkl\n",
      "Loading file: batch_dna_110.pkl\n",
      "Loading file: batch_dna_111.pkl\n",
      "Loading file: batch_dna_112.pkl\n",
      "Loading file: batch_dna_113.pkl\n",
      "Loading file: batch_dna_114.pkl\n",
      "Loading file: batch_dna_115.pkl\n",
      "Loading file: batch_dna_116.pkl\n",
      "Loading file: batch_dna_117.pkl\n",
      "Loading file: batch_dna_118.pkl\n",
      "Loading file: batch_dna_119.pkl\n",
      "Loading file: batch_dna_120.pkl\n",
      "Loading file: batch_dna_121.pkl\n",
      "Loading file: batch_dna_122.pkl\n",
      "Loading file: batch_dna_123.pkl\n",
      "Loading file: batch_dna_124.pkl\n",
      "Loading file: batch_dna_125.pkl\n",
      "Loading file: batch_dna_126.pkl\n",
      "Loading file: batch_dna_127.pkl\n",
      "Loading file: batch_dna_128.pkl\n",
      "Loading file: batch_dna_129.pkl\n",
      "Loading file: batch_dna_130.pkl\n",
      "Loading file: batch_dna_131.pkl\n",
      "Loading file: batch_dna_132.pkl\n",
      "Loading file: batch_dna_133.pkl\n",
      "Loading file: batch_dna_134.pkl\n",
      "Loading file: batch_dna_135.pkl\n",
      "Loading file: batch_dna_136.pkl\n",
      "Loading file: batch_dna_137.pkl\n",
      "Loading file: batch_dna_138.pkl\n",
      "Loading file: batch_dna_139.pkl\n",
      "Loading file: batch_dna_140.pkl\n",
      "Loading file: batch_dna_141.pkl\n",
      "Loading file: batch_dna_142.pkl\n",
      "Loading file: batch_dna_143.pkl\n",
      "Loading file: batch_dna_144.pkl\n",
      "Loading file: batch_dna_145.pkl\n",
      "Loading file: batch_dna_146.pkl\n",
      "Loading file: batch_dna_147.pkl\n",
      "Loading file: batch_dna_148.pkl\n",
      "Loading file: batch_dna_149.pkl\n",
      "Loading file: batch_dna_150.pkl\n",
      "Loading file: batch_dna_151.pkl\n",
      "Loading file: batch_dna_152.pkl\n",
      "Loading file: batch_dna_153.pkl\n",
      "Loading file: batch_dna_154.pkl\n",
      "Loading file: batch_dna_155.pkl\n",
      "Loading file: batch_dna_156.pkl\n",
      "Loading file: batch_dna_157.pkl\n",
      "Loading file: batch_dna_158.pkl\n",
      "Loading file: batch_dna_159.pkl\n",
      "Loading file: batch_dna_160.pkl\n",
      "Loading file: batch_dna_161.pkl\n",
      "Loading file: batch_dna_162.pkl\n",
      "Loading file: batch_dna_163.pkl\n",
      "Loading file: batch_dna_164.pkl\n",
      "Loading file: batch_dna_165.pkl\n",
      "Loading file: batch_dna_166.pkl\n",
      "Loading file: batch_dna_167.pkl\n",
      "Loading file: batch_dna_168.pkl\n",
      "Loading file: batch_dna_169.pkl\n",
      "Loading file: batch_dna_170.pkl\n",
      "Loading file: batch_dna_171.pkl\n",
      "Loading file: batch_dna_172.pkl\n",
      "Loading file: batch_dna_173.pkl\n",
      "Loading file: batch_dna_174.pkl\n",
      "Loading file: batch_dna_175.pkl\n",
      "Loading file: batch_dna_176.pkl\n",
      "Loading file: batch_dna_177.pkl\n",
      "Loading file: batch_dna_178.pkl\n",
      "Loading file: batch_dna_179.pkl\n",
      "Loading file: batch_dna_180.pkl\n",
      "Loading file: batch_dna_181.pkl\n",
      "Loading file: batch_dna_182.pkl\n",
      "Loading file: batch_dna_183.pkl\n",
      "Loading file: batch_dna_184.pkl\n",
      "Loading file: batch_dna_185.pkl\n",
      "Loading file: batch_dna_186.pkl\n",
      "Loading file: batch_dna_187.pkl\n",
      "Loading file: batch_dna_188.pkl\n",
      "Loading file: batch_dna_189.pkl\n",
      "Loading file: batch_dna_190.pkl\n",
      "Loading file: batch_dna_191.pkl\n",
      "Loading file: batch_dna_192.pkl\n",
      "Loading file: batch_dna_193.pkl\n",
      "Loading file: batch_dna_194.pkl\n",
      "Loading file: batch_dna_195.pkl\n",
      "Loading file: batch_dna_196.pkl\n",
      "Loading file: batch_dna_197.pkl\n",
      "Loading file: batch_dna_198.pkl\n",
      "Loading file: batch_dna_199.pkl\n",
      "Loading file: batch_dna_200.pkl\n",
      "Loading file: batch_dna_201.pkl\n",
      "Loading file: batch_dna_202.pkl\n",
      "Loading file: batch_dna_203.pkl\n",
      "Loading file: batch_dna_204.pkl\n",
      "Loading file: batch_dna_205.pkl\n",
      "Loading file: batch_dna_206.pkl\n",
      "Loading file: batch_dna_207.pkl\n",
      "Loading file: batch_dna_208.pkl\n",
      "Loading file: batch_dna_209.pkl\n",
      "Loading file: batch_dna_210.pkl\n",
      "Loading file: batch_dna_211.pkl\n",
      "Loading file: batch_dna_212.pkl\n",
      "Loading file: batch_dna_213.pkl\n",
      "Loading file: batch_dna_214.pkl\n",
      "Loading file: batch_dna_215.pkl\n",
      "Loading file: batch_dna_216.pkl\n",
      "Loading file: batch_dna_217.pkl\n",
      "Loading file: batch_dna_218.pkl\n",
      "Loading file: batch_dna_219.pkl\n",
      "Loading file: batch_dna_220.pkl\n",
      "Loading file: batch_dna_221.pkl\n",
      "Loading file: batch_dna_222.pkl\n",
      "Loading file: batch_dna_223.pkl\n",
      "Loading file: batch_dna_224.pkl\n",
      "Loading file: batch_dna_225.pkl\n",
      "Loading file: batch_dna_226.pkl\n",
      "Loading file: batch_dna_227.pkl\n",
      "Loading file: batch_dna_228.pkl\n",
      "Loading file: batch_dna_229.pkl\n",
      "Loading file: batch_dna_230.pkl\n",
      "Loading file: batch_dna_231.pkl\n",
      "Loading file: batch_dna_232.pkl\n",
      "Loading file: batch_dna_233.pkl\n",
      "Loading file: batch_dna_234.pkl\n",
      "Loading file: batch_dna_235.pkl\n",
      "Loading file: batch_dna_236.pkl\n",
      "Loading file: batch_dna_237.pkl\n",
      "Loading file: batch_dna_238.pkl\n",
      "Loading file: batch_dna_239.pkl\n",
      "Loading file: batch_dna_240.pkl\n",
      "Loading file: batch_dna_241.pkl\n",
      "Loading file: batch_dna_242.pkl\n",
      "Loading file: batch_dna_243.pkl\n",
      "Loading file: batch_dna_244.pkl\n",
      "Loading file: batch_dna_245.pkl\n",
      "Loading file: batch_dna_246.pkl\n",
      "Loading file: batch_dna_247.pkl\n",
      "Loading file: batch_dna_248.pkl\n",
      "Loading file: batch_dna_249.pkl\n",
      "Loading file: batch_dna_250.pkl\n",
      "Loading file: batch_dna_251.pkl\n",
      "Loading file: batch_dna_252.pkl\n",
      "Loading file: batch_dna_253.pkl\n",
      "Loading file: batch_img_0.pkl\n",
      "Loading file: batch_img_1.pkl\n",
      "Loading file: batch_img_2.pkl\n",
      "Loading file: batch_img_3.pkl\n",
      "Loading file: batch_img_4.pkl\n",
      "Loading file: batch_img_5.pkl\n",
      "Loading file: batch_img_6.pkl\n",
      "Loading file: batch_img_7.pkl\n",
      "Loading file: batch_img_8.pkl\n",
      "Loading file: batch_img_9.pkl\n",
      "Loading file: batch_img_10.pkl\n",
      "Loading file: batch_img_11.pkl\n",
      "Loading file: batch_img_12.pkl\n",
      "Loading file: batch_img_13.pkl\n",
      "Loading file: batch_img_14.pkl\n",
      "Loading file: batch_img_15.pkl\n",
      "Loading file: batch_img_16.pkl\n",
      "Loading file: batch_img_17.pkl\n",
      "Loading file: batch_img_18.pkl\n",
      "Loading file: batch_img_19.pkl\n",
      "Loading file: batch_img_20.pkl\n",
      "Loading file: batch_img_21.pkl\n",
      "Loading file: batch_img_22.pkl\n",
      "Loading file: batch_img_23.pkl\n",
      "Loading file: batch_img_24.pkl\n",
      "Loading file: batch_img_25.pkl\n",
      "Loading file: batch_img_26.pkl\n",
      "Loading file: batch_img_27.pkl\n",
      "Loading file: batch_img_28.pkl\n",
      "Loading file: batch_img_29.pkl\n",
      "Loading file: batch_img_30.pkl\n",
      "Loading file: batch_img_31.pkl\n",
      "Loading file: batch_img_32.pkl\n",
      "Loading file: batch_img_33.pkl\n",
      "Loading file: batch_img_34.pkl\n",
      "Loading file: batch_img_35.pkl\n",
      "Loading file: batch_img_36.pkl\n",
      "Loading file: batch_img_37.pkl\n",
      "Loading file: batch_img_38.pkl\n",
      "Loading file: batch_img_39.pkl\n",
      "Loading file: batch_img_40.pkl\n",
      "Loading file: batch_img_41.pkl\n",
      "Loading file: batch_img_42.pkl\n",
      "Loading file: batch_img_43.pkl\n",
      "Loading file: batch_img_44.pkl\n",
      "Loading file: batch_img_45.pkl\n",
      "Loading file: batch_img_46.pkl\n",
      "Loading file: batch_img_47.pkl\n",
      "Loading file: batch_img_48.pkl\n",
      "Loading file: batch_img_49.pkl\n",
      "Loading file: batch_img_50.pkl\n",
      "Loading file: batch_img_51.pkl\n",
      "Loading file: batch_img_52.pkl\n",
      "Loading file: batch_img_53.pkl\n",
      "Loading file: batch_img_54.pkl\n",
      "Loading file: batch_img_55.pkl\n",
      "Loading file: batch_img_56.pkl\n",
      "Loading file: batch_img_57.pkl\n",
      "Loading file: batch_img_58.pkl\n",
      "Loading file: batch_img_59.pkl\n",
      "Loading file: batch_img_60.pkl\n",
      "Loading file: batch_img_61.pkl\n",
      "Loading file: batch_img_62.pkl\n",
      "Loading file: batch_img_63.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_seen_loc': <multimodal_dataset.MultiModalDataset at 0x7f440cd99910>,\n",
       " 'val_unseen_loc': <multimodal_dataset.MultiModalDataset at 0x7f440ce31e90>,\n",
       " 'test_seen_loc': <multimodal_dataset.MultiModalDataset at 0x7f440c353690>,\n",
       " 'test_unseen_loc': <multimodal_dataset.MultiModalDataset at 0x7f43f5f9e110>}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multimodal_dataset import MultiModalDataset\n",
    "from load_embeddings import load_dna_embeddings, load_img_embeddings\n",
    "\n",
    "all_dna_features = load_dna_embeddings()\n",
    "all_image_features = load_img_embeddings()\n",
    "\n",
    "all_dna_len = list(map(lambda s: len(s.strip()), mat['all_string_dnas']))\n",
    "dna_str_len_mapping: dict[int,int] = {}\n",
    "\n",
    "def dna_str_len_to_int(s_len):\n",
    "    if s_len not in dna_str_len_mapping:\n",
    "        dna_str_len_mapping[s_len] = len(dna_str_len_mapping)\n",
    "    return dna_str_len_mapping[s_len]\n",
    "\n",
    "# def all_dna_len_token():\n",
    "#     return list(map(dna_str_len_to_int, all_dna_len))\n",
    "\n",
    "all_dna_len_tokens = list(map(dna_str_len_to_int, all_dna_len))\n",
    "all_dna_len_tokens = np.array(all_dna_len_tokens, dtype=np.int64)\n",
    "\n",
    "species2genus = mat['species2genus']-1\n",
    "\n",
    "\n",
    "genus_species = dict()\n",
    "max_specie_in_genus = 0\n",
    "for genus_id, genus in pd.DataFrame(species2genus, columns=['genus']).groupby('genus'):\n",
    "    specie_indices = genus.index.tolist()\n",
    "    genus_species[genus_id] = specie_indices\n",
    "    if len(specie_indices) > max_specie_in_genus:\n",
    "        max_specie_in_genus = len(specie_indices)\n",
    "\n",
    "datasets = {\n",
    "    indicies_type:MultiModalDataset(\n",
    "        mat['all_string_dnas'][(inds:=mat[indicies_type].flatten())],\n",
    "        mat['all_images'][inds],\n",
    "        np.transpose(mat['all_labels'], (1,0))[inds],\n",
    "        dna_str_len_mapping,\n",
    "        species2genus,\n",
    "        genus_species,\n",
    "        None,\n",
    "        None,\n",
    "        dna_embeddings=all_dna_features[inds],\n",
    "        img_embeddings=all_image_features[inds]\n",
    "    )\n",
    "    for indicies_type in [\"val_seen_loc\", \"val_unseen_loc\", \"test_seen_loc\", \"test_unseen_loc\"]\n",
    "}\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "69e5010a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating val_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 32 but got size 96 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmain_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/insect-classification-deeplearning/models.py:579\u001b[0m, in \u001b[0;36mMainClassifier.evaluate\u001b[0;34m(self, datasets)\u001b[0m\n\u001b[1;32m    571\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    572\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    573\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m    577\u001b[0m )\n\u001b[1;32m    578\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (data_name, results)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4254\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4251\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4253\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4254\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4255\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4257\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   4258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   4259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4264\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4449\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4446\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   4448\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 4449\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4450\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4451\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4453\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4665\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   4664\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4665\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4666\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m   4668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:3884\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3882\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3883\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 3884\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3885\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3886\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/insect-classification-deeplearning/models.py:407\u001b[0m, in \u001b[0;36mMainClassifier.forward\u001b[0;34m(self, dna_len_tokens, image_inputs, dna_inputs, dna_emb, img_emb, genus, local_specie_lbl, labels)\u001b[0m\n\u001b[1;32m    402\u001b[0m         img_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_embedder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimage_inputs)\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# print(\"DNA Embedding Shape:\", dna_emb.shape, \"Image Embedding Shape:\", img_emb.shape)\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m fused_emb, dna_len_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfusion_embedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdna_len_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdna_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_emb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, fused_dim]\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# print(\"Fused Embedding Shape:\", fused_emb.shape)\u001b[39;00m\n\u001b[1;32m    410\u001b[0m genus_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenus_classifier(fused_emb, dna_len_emb)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/insect-classification-deeplearning/models.py:160\u001b[0m, in \u001b[0;36mAttentionFusion.forward\u001b[0;34m(self, dna_len_tokens, dna_emb, img_emb)\u001b[0m\n\u001b[1;32m    157\u001b[0m dna_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_dna(dna_emb)\n\u001b[1;32m    158\u001b[0m img_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_img(img_emb)\n\u001b[0;32m--> 160\u001b[0m dna_final_emb \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdna_len_attn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdna_len_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdna_attn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdna_proj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, 1, dna_len_dim + dna_dim]\u001b[39;00m\n\u001b[1;32m    162\u001b[0m seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([dna_final_emb, img_attn \u001b[38;5;241m*\u001b[39mimg_proj], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [batch, concat_dim]\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Aggregate embelddings (mean pooling)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# fused = attn_out.mean(dim=1)  # [batch, D]\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Optional FFN\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 32 but got size 96 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "dict(main_classifier.evaluate(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557fe077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_embedder {'dna_dim': 512, 'img_dim': 768, 'fused_dim': 258, 'dna_len_dim': 32, 'num_distinct_dna_len': 120, 'proj_dna_dim': 96, 'proj_img_dim': 128, 'dropout': 0.2}\n",
      "Loaded model config: {'fusion_embedder': {'dna_dim': 512, 'img_dim': 768, 'fused_dim': 258, 'dna_len_dim': 32, 'num_distinct_dna_len': 120, 'proj_dna_dim': 96, 'proj_img_dim': 128, 'dropout': 0.2}, 'genus_classifier': {'fused_dim': 258, 'hidden_dim': 744, 'genus_n_classes': 372, 'dropout': 0.1, 'dna_len_dim': 32}, 'local_specie_classifier': {'fused_dim': 258, 'genus_n_classes': 372, 'reduced_fused_dim': 128, 'max_specie_in_genus': 23, 'genus_embedding_dim': 64, 'specie_decoder_hidden_dim': 256, 'dropout': 0.1, 'dna_len_dim': 32}}\n",
      "AttentionFusion(\n",
      "  (dna_len_emb): Embedding(120, 32)\n",
      "  (proj_dna): Linear(in_features=512, out_features=96, bias=True)\n",
      "  (proj_img): Linear(in_features=768, out_features=128, bias=True)\n",
      "  (weight_dna_len): Linear(in_features=32, out_features=1, bias=False)\n",
      "  (weight_dna): Linear(in_features=512, out_features=1, bias=False)\n",
      "  (weight_img): Linear(in_features=768, out_features=1, bias=False)\n",
      "  (ffn): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=258, bias=True)\n",
      "  )\n",
      ") 258 GenusClassifier(\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=290, out_features=744, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=744, out_features=372, bias=True)\n",
      "  )\n",
      ") 258\n",
      "MainClassifier(\n",
      "  (fusion_embedder): AttentionFusion(\n",
      "    (dna_len_emb): Embedding(120, 32)\n",
      "    (proj_dna): Linear(in_features=512, out_features=96, bias=True)\n",
      "    (proj_img): Linear(in_features=768, out_features=128, bias=True)\n",
      "    (weight_dna_len): Linear(in_features=32, out_features=1, bias=False)\n",
      "    (weight_dna): Linear(in_features=512, out_features=1, bias=False)\n",
      "    (weight_img): Linear(in_features=768, out_features=1, bias=False)\n",
      "    (ffn): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=258, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (genus_classifier): GenusClassifier(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=290, out_features=744, bias=True)\n",
      "      (1): Sigmoid()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=744, out_features=372, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (local_specie_classifier): LocalSpecieClassfier(\n",
      "    (fused_proj): Linear(in_features=258, out_features=128, bias=True)\n",
      "    (genus_embedder): Linear(in_features=372, out_features=64, bias=True)\n",
      "    (specie_decoder): Sequential(\n",
      "      (0): Linear(in_features=224, out_features=256, bias=True)\n",
      "      (1): Sigmoid()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=23, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (genus_criterion): CrossEntropyLoss()\n",
      "  (specie_criterion): CrossEntropyLoss()\n",
      "  (total_criterion): CrossEntropyLoss()\n",
      ")\n",
      "Evaluating val_seen_loc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['dna_emb'] = torch.tensor(self.dna_embeddings[idx], dtype=torch.float32)\n",
      "/home/hajibagher/insect-classification-deeplearning/multimodal_dataset.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  res['img_emb'] = torch.tensor(self.img_embeddings[idx], dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 32 but got size 96 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m main_classifier \u001b[38;5;241m=\u001b[39m MainClassifier\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results_20250827T234918-final\u001b[39m\u001b[38;5;124m\"\u001b[39m, mat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecies2genus\u001b[39m\u001b[38;5;124m'\u001b[39m], genus_species)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(main_classifier)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmain_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# main_classifier = MainClassifier(mat['species2genus'], genus_species, None, None, fusion_embedder, genus_classifier,local_specie_classifier,alpha=2, beta=0, theta=0,).to(device)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# print(main_classifier)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# main_classifier.load_model(\"results_20250819T030148-final\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     lr=1e-3\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m~/insect-classification-deeplearning/models.py:579\u001b[0m, in \u001b[0;36mMainClassifier.evaluate\u001b[0;34m(self, datasets)\u001b[0m\n\u001b[1;32m    571\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    572\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    573\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m    577\u001b[0m )\n\u001b[1;32m    578\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (data_name, results)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4254\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4251\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4253\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4254\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4255\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4257\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   4258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   4259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4264\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4449\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4446\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   4448\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 4449\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4450\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4451\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4453\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4665\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   4664\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4665\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4666\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m   4668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:3884\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3882\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3883\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 3884\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3885\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3886\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/insect-classification-deeplearning/models.py:407\u001b[0m, in \u001b[0;36mMainClassifier.forward\u001b[0;34m(self, dna_len_tokens, image_inputs, dna_inputs, dna_emb, img_emb, genus, local_specie_lbl, labels)\u001b[0m\n\u001b[1;32m    402\u001b[0m         img_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_embedder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimage_inputs)\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# print(\"DNA Embedding Shape:\", dna_emb.shape, \"Image Embedding Shape:\", img_emb.shape)\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m fused_emb, dna_len_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfusion_embedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdna_len_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdna_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_emb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, fused_dim]\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# print(\"Fused Embedding Shape:\", fused_emb.shape)\u001b[39;00m\n\u001b[1;32m    410\u001b[0m genus_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenus_classifier(fused_emb, dna_len_emb)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/insect-classification-deeplearning/models.py:160\u001b[0m, in \u001b[0;36mAttentionFusion.forward\u001b[0;34m(self, dna_len_tokens, dna_emb, img_emb)\u001b[0m\n\u001b[1;32m    157\u001b[0m dna_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_dna(dna_emb)\n\u001b[1;32m    158\u001b[0m img_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_img(img_emb)\n\u001b[0;32m--> 160\u001b[0m dna_final_emb \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdna_len_attn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdna_len_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdna_attn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdna_proj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, 1, dna_len_dim + dna_dim]\u001b[39;00m\n\u001b[1;32m    162\u001b[0m seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([dna_final_emb, img_attn \u001b[38;5;241m*\u001b[39mimg_proj], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [batch, concat_dim]\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Aggregate embelddings (mean pooling)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# fused = attn_out.mean(dim=1)  # [batch, D]\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Optional FFN\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 32 but got size 96 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Evaluate:\n",
    "import models\n",
    "reload(models)\n",
    "from models import AttentionFusion, GenusClassifier, LocalSpecieClassfier, MainClassifier, multimodal_collector\n",
    "\n",
    "fusion_embedder = AttentionFusion(dna_dim=512,img_dim=768,dna_len_dim=32, fused_dim=258, proj_dna_dim=128-32, proj_img_dim=128, dropout=0.2)\n",
    "print(\"fusion_embedder\", fusion_embedder._config)\n",
    "# print(\"Fusion model created. fused dim: \", fusion_embedder.fused_dim)\n",
    "genus_classifier = GenusClassifier(fusion_embedder.fused_dim,dropout=0.1, dna_len_dim=32)\n",
    "local_specie_classifier = LocalSpecieClassfier(fusion_embedder.fused_dim,reduced_fused_dim=128, specie_decoder_hidden_dim=256, dropout=0.1,dna_len_dim=32)\n",
    "\n",
    "main_classifier = MainClassifier.load_model(\"./results_20250827T234918-final\", mat['species2genus'], genus_species).to(device)\n",
    "print(main_classifier)\n",
    "\n",
    "# main_classifier = MainClassifier(mat['species2genus'], genus_species, None, None, fusion_embedder, genus_classifier,local_specie_classifier,alpha=2, beta=0, theta=0,).to(device)\n",
    "# print(main_classifier)\n",
    "# main_classifier.load_model(\"results_20250819T030148-final\")\n",
    "# train_indices = (mat['train_loc'] - 1).flatten()  # Get train indices\n",
    "# train_dataset = MultiModalDataset(mat['all_string_dnas'][train_indices], mat['all_images'][train_indices], np.transpose(mat['all_labels'], (1,0))[train_indices], dna_str_len_mapping, species2genus, genus_species, None, None, dna_embeddings=all_dna_features[train_indices], img_embeddings=all_image_features[train_indices])\n",
    "# main_classifier.fit(\n",
    "#     train_dataset,\n",
    "#     None,\n",
    "#     batch_size=64,\n",
    "#     epochs=1,\n",
    "#     eval_steps=200,\n",
    "#     save_steps=400,\n",
    "#     lr=1e-3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1352eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_classifier = MainClassifier(mat['species2genus'], genus_species, None, None, None, None,local_specie_classifier,alpha=2, beta=0, theta=0,).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520656c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object MainClassifier.evaluate at 0x7f43f5b6ee40>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
